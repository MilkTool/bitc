/* -*- mode: c++ -*-  */

/** @page MixFixProcessing (Plan for) MixFix Processing
 *
 * BitC accepts mixfix expressions. This note describes some of the
 * implementation issues.
 *
 * @section MixFixWhatIs What is MixFix?
 *
 * A mixfix declaration takes one of the forms:
 *
 * @verbatim
mixfix _+_   5     // infix
mixfix _!    9     // postfix
mixfix not_  6     // prefix
mixfix (_)   6     // outfix  (term?)
mixfix _[_]  6     // postfix with multiple expressions
@endverbatim
 *
 * These declarations have the effect of augmenting the expression
 * grammar. Expressions in the primary grammar have some "primary"
 * cases that are higher precedence than any mixfix production
 * (e.g. "a.b"). When the primary parser processes the mixfix_expr
 * production, it gathers the elements into a linear list consisting
 * of expressions. Some of these really are expression nodes that
 * resulted from primary expression parsing. Most are
 * identifiers. Some of the identifiers turn out to be mixfix
 * quasi-keywords introduced by mixfix declarations. Those will be
 * processed/rearranged by the mixfix processor here.
 *
 * The BitC mixfix design borrows syntax from the Agda programming
 * language. It also borrows the idea that "interior" (fully
 * bracketed) holes can accept expressions having any precedence. That
 * is: precedence rules are only applied at edge holes. In contrast to
 * Agda, we retain the tradition that precedence relations are
 * transitive. While we treat quasi-keywords as keywords while they
 * are in scope (meaning mainly that they cannot be rebound), we do
 * <em>not</em> require that they be unique. In particular, it is
 * perfectly okay in BitC to introduce the mixfix rules:
 *
 * @verbatim
mixfix while_do_  5
mixfix until_do_  5
@endverbatim
 *
 * even though they both use "do" as a quasi-keyword. The fact that
 * quasi-keywords are not unique somewhat increases the challenge of
 * the BitC parsing problem in comparison to other mixfix
 * implementations.
 *
 * @note Actually, this example isn't quite legal because
 * <code>while</code>, <code>until</code>,  and <code>do</code> are
 * keywords, but with the introduction of the mixfix mechanism and the
 * (forthcoming) support for automatic thunking these may move out of
 * the core and get specified as mixfix entries in the prelude.
 *
 * @section MixFixPrecedence Handling of Precedence
 *
 * One of the back-and-forth discussions in the literature is whether
 * precedence relations in mixfix should be transitive. For
 * example, if we know <code>_AND_ &lt; _==_</code> and <code>_==_
 * &lt; _+_</code>, does it follow that <code>_AND_ &lt; _+_</code>
 * (which is arguably nonsense)? Danielsson argues that this is undesirable,
 * because transitive precedence can lead to some odd cases. My view
 * is that uses of mixfix tend to fall into two cases:
 *
 * - Most uses of mixfix "fit" the regular precedence hierarchy
 *   comfortably. That is: you can find an available spot for them in
 *   the available precedence hierarchy *and* applying the precedence
 *   rules in a transitive way doesn't result in any surprises.
 * - A few uses of mixfix are sophisticated, and are introducing
 *   completely different syntactic schemas than the ones that are
 *   conventional in programming languages. Either there aren't
 *   enough levels available to insert the right operators in the
 *   desired ways, or it is truly necessary to change the
 *   <em>relative</em> precedences of certain operators in the context
 *   of the new sub-language, or perhaps it is desired to
 *   <em>remove</em> some operators that are part of the set provided
 *   by the prelude. That is: you are designing a new, specialized
 *   expression language rather than tweaking an existing one.
 *
 * My (unsubstantiated) belief is that the perceived problems with
 * transitive precedence relations arise mainly in the second
 * situation, and are a result of the fact that existing
 * implementations don't provide a first-class notion of syntax
 * rules. That's easily remedied without too much complexity, so we're
 * going to give it a try in BitC.
 *
 * @section MixFixTheoryOfOperation Theory of Operation
 *
 * MixFix itself is conceptually straightforward, but not documented
 * in a way that is particularly accessible to first-time implementors
 * (like myself). We are presented with a linear list of expressions,
 * some of which are quasi-keywords. For example, the mixfix rule:
 *
 * @verbatim
mixfix _[_]  6     // postfix with multiple expressions
@endverbatim
 * 
 * introduces the quasi-keywords '[' and ']'. While this rule is in
 * scope, these identifiers will be treated as keywords. The rule
 * also introduces what amounts to a grammar production
 *
 * @verbatim
mixfix_expr: mixfix_expr '[' mixfix_expr ']'  %prec 6
@endverbatim
 *
 * The job of the mixfix layer is to implement these productions. The
 * implementation challenge derives from the fact that the set of
 * productions is not fixed: mixfix declarations can (eventually)
 * occur in local scopes. In the classic table-driven parsing
 * techniques, <em>adding</em> a production is (barely) tractable, but
 * <em>deleting</em> one is pretty darned expensive. So, for example,
 * the AGDA implementation uses memoizing parser combinators, and (I
 * assume - haven't checked) flushes the memoization cache when a
 * production is removed.
 *
 * The implementation chosen here here is simply to do an
 * interpretive, back-tracking GLR parser. This avoids all (or at
 * least most) of the challenges of inserting and removing
 * productions. Reading between the lines, I think there is a concern
 * among implementors that this is an O(N<sup>3</sup>) algorithm, but
 * it's important to remember that this is an asymptotic worst case
 * rather than the typical case. In the context of a mixfix
 * implementation, several factors mitigate this bound:
 *
 * - Two "holes" are never adjacent.
 * - No eta-productions (rules matching empty) are present.
 * - Ambiguities are rare in practice. The "right" production, when
 *   one is present, can generally be determined by looking at the
 *   next two items in the input stream. This typically reduces the
 *   number of productions that must be considered down to one.
 * - Most productions are infix, and selection options on these are
 *   bounded by precedence rules. Two element lookahead (which is
 *   possible because of the "no two holes" rule is often enough to
 *   further filter the candidate rules.
 * - For human reasons, expressions don't tend to get too large before
 *   parenthesis start to appear. This has the effect of bounding N.
 *
 * I could be completely wrong about the combined impact of this on
 * the observed complexity, but I'm going to give it a try anyway. If
 * nothing else, it will be interesting to measure how much
 * back-tracking actually occurs on real input.
 *
 * @subsection MixFixParseDataStructures Supporting Data Structures
 *
 * The implementation maintains some supporting data structures:
 *
 * - @b MixRule, which records for each rule its name, the RHS elements
 *   of the production, its precedence, its fixity, and its
 *   associativity. The length of the RHS vector matches the "reduce
 *   size" of the production (the number of elements on the parse
 *   stack to remove when reducing).
 *
 * - @b QuasiKeyword, a mapping from strings (identifiers) to a
 *   structure of counters. This structure records:
 *   - How many times the quasi-keyword is in use in some production
 *   - How many times it appears as the first element of a rule
 *   - How many times it appears in some rule just before a trailing hole
 *   - How many times it appears in some rule just after a leading hole
 *   Counters are used instead of bits in order to facilitiate rule
 *   deletion.
 *
 * - @b MixContext, a structure that records a mixfix parsing context
 *   and its associated keyword map.
 *
 * The mixfix parser implementation itself is a recursive, predictive,
 * shunting-yard variant. It uses a distinct parse stack and copy of
 * the input for each production it attempts so that it is easier to
 * back-track.
 *
 * There are several aspects of the BitC mixfix specification that
 * simplify or help to optimizer the parsing problem:
 *
 *   - It is never the case that two expression "holes" are adjacent.
 *   - Every mixfix specification has at least one hole.
 *   - There are no eta-productions to consider.
 *   - Every production either starts with a quasi-keyword (an
 *     operator) or an expression.
 *   - There is only one non-terminal: @em mixfix-expr.
 *   - In any place where there is ambiguity of action, either there
 *     is a disambiguating precedence rule or there is an error.
 *
 * @subsection MixFixComplications Complications
 *
 * After getting an initial mixfix implementation working, I stumbled
 * into an unpleasant surprise. The expression:
 *
 * @verbatim
a + (b-1)
@endverbatim
 *
 * got completely mangled, because function application has higher
 * precedence than anything else. In a mixfix parser, the ``+'' is
 * just an idenfitier, so the <code>+(b-1)</code> got processed as a
 * procedure application in the primary parser before processing ever
 * made it into the mixfix layer. The resulting input at the mixfix
 * layer was:
 *
 * @verbatim
a {apply + {apply - b 1}}
@endverbatim
 *
 * Needless to say, this was not quite what I had in mind. The
 * question is: since ``+'' is just an identifier, why are the
 * following two things handled differently?
 *
 * @verbatim
a + (b-1)
a f (b-1)   // invalid
@endverbatim
 *
 * The answer is that they are different because, at the mixfix layer,
 * the ``+'' is not an identifier; it is a quasi-keyword. In
 * consequence, the input pattern <code>+(b-1)</code> does not have an
 * expression on the left, and therefore will not match the rule for
 * application. "Hang on," you say, "the rule for application?"
 *
 * Yes. That's what this whole ``complications'' discussion is leading
 * up to. We can't make decisions about what is an application until
 * we get into the mixfix layer, which leads us to the following chain
 * of conclusions:
 *
 * - The mixfix layer has to take over the handling of application, so
 *   we need a rule for _(_). 
 * - Since BitC procedures are n-ary, this means that the mixfix layer
 *   also has to take over handling of _,_ in order to handle
 *   arguments, but...
 * - Once mixfix handles _,_ it also needs to handle pair
 *   construction, some of the list convenience syntax, and vector
 *   initializers.
 * - Since those "take over" array indexing, mixfix needs to process
 *   that too. 
 * - Of these, pair construction is a bit unpleasant, because it means
 *   that the (_) rule might mean either ordinary parenthesization or
 *   the pair construction convenience syntax!
 * - And just for fun, mixfix also has to handle _._, because after it
 *   takes over parenthesis we still need to be able to process
 *   <code>(a).b</code>.
 *
 * Here is how I ended up sorting this all out:
 *
 * First, remember that the mixfix layer is building ASTs, and that it
 * is purely context free. Because of this, my description above of
 * the apply pattern doesn't work, and here's what we need to do to
 * sort out pairs and application:
 *
 * - Initially, we treat <code>_,_</code> as building apply ASTs of the
 *   form <code>{apply _,_ e1 e2}</code>
 * - Similarly, we treat <code>(_)</code> as building apply ASTs of the
 *   form {apply <code>(_)</code> e1}
 * - We handle procedure application with the special-case pattern
 *   ``<code>_&nbsp;_</code>'', 
 *   where the second expression is required to be of the form <code>{apply
 *   (_) e1}</code>. So a procedure call with show up as
 *   <code>{ apply __ { apply (_) e1 }}</code> where the <em>e1</em>
 *   will be an 
 *   apply of <code>_,_</code> exactly if the procedure takes multiple arguments.
 * - We handle array indexing similarly to procedure calls using 
 *   ``<code>_&nbsp;_</code>'', 
 *   where the second expression is required to be of the form <code>{apply
 *   [_] e1}</code>.
 * - For list literals <code>[ a, b, c ]</code>, we end up with:
 *   <code>{ apply (_) { apply [_] e1} }</code>
 * - For pair literals <code>(a, b, c)</code>, we end up with:
 *   <code>{ apply (_) { apply _,_ e1 e2} }</code>
 * - For vector literals, we may end up with:
 *   <code>{ apply MakeVector { apply _,_ e1 e2} }</code> or 
 *   <code>{ apply MakeVector (singleton expr) }</code> or 
 *
 * The first important point in all of this is to notice that an
 * <code>{apply _,_
 * e}</code> is <em>always</em> ``wrapped'' by something else in
 * well-formed input, and conversely, that an <code>{apply (_)
 * e}</code> node which is merely a parenthesized expression can be
 * identified by virtue of <em>not</em> being wrapped. 
 *
 * The second important point is that the operator precedence rules
 * for <code>_,_</code>, <code>(_)</code>, and ``<code>_&nbsp;_</code>''
 * (and friends) work out correctly, primarily because
 * <code>_,_</code> always appears inside a closed form.
 *
 * The end result is that we can let the mixfix layer assemble an
 * expression tree by running the precedence-based parser, and then
 * make a post-pass to rewrite that tree into the proper form for
 * literal constructions, vector constructions, and applications.
 *
 * Which, after seeing the initial mess created by:
 *
 * @verbatim
a + (b-1)
@endverbatim
 *
 * is a feasibility conclusion that I was <em>very</em> relieved to reach!
 *
 * @subsection MixFixImplIssues Issues on Implementation
 *
 * When I went to actually implement, I found that the preferred parse
 * rules for handling <code>_,_</code> are not possible. Ideally, the
 * primary parser would ensure that <code>_,_</code> only arises
 * within the legal bracketing forms <code>(_)</code> or
 * <code>[_]</code>. In practice, this causes a long list of parse
 * conflicts. The workaround is to simply accept ``,'' as if it were
 * an identifier, and leave the syntactic issue to be diagnosed in the
 * mixfix handler through the absence of any <code>,_</code> or
 * <code>_,</code> productions.
 */
